architectural-style-recognition
==============================

Development of a model for the classification of architectural styles of buildings.

Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    └── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io

Model card
==========


Model details
------------

- Authors: Andrea Basile, Roberto Lorusso, Antonio Iacovazzi, Emanuele Pomponio

- Model date: 28 June 2022

- Model Version: 2.2.3

- Model Type: CNN based on Mobile-NetV2 architecture 


The model we used in our project is composed by 4 Layers:

- Input layer: used for establish the shape of input, in this case an image 224 x 224 x 3

- MobileNetV2: MobileNet is a pretrained CNN, suited for devices with low computational resources. We retrained all the parameters of this network in order to get better accuracy.

- Dropout layer: randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.

- Dense layer: the dense layer performs a matrix- vector multiplication. The output generated by the dense layer is an 10 dimensional vector in order to obtain the classification through the ac- tivation function "softmax".


### Parameters 

The model was trained with the following setting for the parameters:
-  Stochastic Gradient Descent optimizer with learning rate of 0.005 and momentum of 0.9
-  Number of epochs = 10
-  Batch size = 32
-  steps per epoch = train set size / batch size
- validation steps = validation set size / batch size
- Dropout rate = 0.4
- L2 regularizer = 0.005



### Resources


The dataset is publicly available from kaggle at:
<a>https://www.kaggle.com/datasets/wwymak/architecture-dataset</a>

#### Related Works: 

- Zhe Xu et al. “Architectural Style Classification Using Multinomial Latent Logistic Regression”. In: ECCV. 2014.

- Zhang J. et al Wang B. Zhang S. “Architectural style classification based on CNN and channel spatial attention”. In: SIViP. 2022.

- Mark Sandler et al. “Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”. In: CoRR abs/1801.04381 (2018). arXiv: 1801.04381. url: <a>http://arxiv.org/abs/1801.04381 </a>

- Chi-Feng Wang. A Basic Introduction to Separable Convolutions. 2018 url: <a>https://towardsdatascience.com/ a-basic-introduction-to-separable-convolutions-b99ec3102728</a>


### License 

MIT License

### Contacts

Further details can be given at the following contacts:   

- a.basile99@studenti.uniba.it
- r.lorusso62@studenti.uniba.it


### Intended use

The principal stakeholders are generic users with the intent of recognizing an architectural style. The model has a user-interface developed with a Telegram chat bot. 
Another context of usage can be the didactic one, as every organization can access to the chat bot. 

### Factors

The training and validatoin phases are made by using only images captured at daylight time. In the test phase there could be low accuracy associated to night images.

All the experiments were carried out on Google Colab platform with the following setting:

- Python 2.7
- TensorFlow 2.8.0
- GPU Hardware Accelerator


### Metrics

The accuracy obtained by the model in the training phase is around 95%, while the validation accuracy is around the 84%. 

During the test phase, the model reached an accuracy of 84% on a test set of 450 images. 


### Training data 

The training data consists of 80% of our dataset, the remaining 20% is divided between validation data and test data.

#### Motivation 

The main motivation behind the choice of the dataset is that it is the largest publicly available data set for architectural style classification.

#### Preprocessing

Since the dataset was highly unbalanced, we decided to perform both data balancing and data augmentation. The goals of these decisions are: 

- Equally represented classes with 450 images each,
- Mapping features of the classes regardless of the eventual presence of noise in the images. 

Data balancing is performed by duplicating images in the classes. 
Data augmentation is performed by appliying the following transformations on the training images: 

- Re-scaling normalization: Neural networks pro- cess inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.

- Mean-STD Normalization: Data normalization is an important step in the training process of a neural network. By normalizing the data to a uniform mean of 0 and a standard deviation of 1, faster convergence is achieved.

- Random-rotation

- Random-scaling

- Random-zoom


### Caveats and Recommendations

Since the model was trained on a limited number of architectural styles, the predictions can be wrong when the model tries to classify unseen architectural styles, classifying the image with the most similar one. 
The informations gained after its use must be verified by trustful sources. 

Since architectural styles can enclose many other styles, the predicitons can be sensitive to this kind of characteristics.

As mentioned before night images can suffer of low accuracy in the process of prediction, we suggest to run predictions on images captured at day light time. 


Dataset Card for "Dataset of buildings with associated architectural styles, based on Zhe Xu et al. 'Architectural Style Classification Using Multinomial Latent Logistic Regression'"
==========
## Table of Contents
- [Table of Contents](#table-of-contents)
- [Dataset Description](#dataset-description)
  - [Dataset Summary](#dataset-summary)
  - [Supported Tasks and Leaderboards](#supported-tasks-and-leaderboards)
  - [Languages](#languages)
- [Dataset Structure](#dataset-structure)
  - [Data Instances](#data-instances)
  - [Data Fields](#data-fields)
  - [Data Splits](#data-splits)
- [Dataset Creation](#dataset-creation)
  - [Curation Rationale](#curation-rationale)
  - [Source Data](#source-data)
  - [Annotations](#annotations)
  - [Personal and Sensitive Information](#personal-and-sensitive-information)
- [Additional Information](#additional-information)
  - [Dataset Curators](#dataset-curators)
  - [Licensing Information](#licensing-information)


## Dataset Description

- **Repository:** <a>https://www.kaggle.com/datasets/wwymak/architecture-dataset</a>
- **Paper:** <a>https://www.semanticscholar.org/paper/Architectural-Style-Classification-Using-Latent-Xu-Tao/bf6fd53680c5ec7b998c60bd75243d5b7cf7f93f?p2df</a>


### Dataset Summary

The dataset is a subset of the one used in the paper "Architectural Style Classification Using Multinomial Latent Logistic Regression", Zhe Xu et al.

The original dataset contains around 5000 images of buildings annotated according to 25 different classes (i.e. architectural styles). 

This number has been reduced to 2343 images and 10 classes in order to reduce time complexity in the training phase.

The 10 classes considered are:
1-Baroque
2-Byzantine
3-Art Deco
4-Art Nuveau
5-Egyptian
6-Ghotic
7-Greek
8-Art Nuveau
9-Romanesque
10-Russian

### Supported Tasks and Leaderboards

The model has been using for the task of classification of architectural styles, reaching an accuracy of around 84% on the test set.


### Languages

As the dataset is comprised of annotated images (in contrast to annotated documents), the language we refer to in only the one used in the annotations, which is exclusively English.

## Dataset Structure

### Data Instances

Each instance is constitued by a 224x224x3 image.

### Data Fields

As the dataset is comprised of images, there are no data fields.

### Data Splits

The training, validation and test proportion of the dataset are respectively 70%, 20% and 10%.

## Dataset Creation

### Curation Rationale

The dataset was created by the original authors of the cited paper to compensate for the lack of publicly available large-scale architectural style databases.

A subset of this dataset has been selected for the model in this project, in order to speed up training times.


### Source Data

#### Initial Data Collection and Normalization

According to the source paper, the dataset has been annotated by querying Wikimedia with the keyword "Architecture_by_style" and then downloading images from subcategories resulting from the query. Those images have then been manually filtered to exclude images of non-buildings, interior decorations, or part of a building, so that the remaining images only contained exterior facades of buildings. Furthermore, styles with too few images were discarded, resulting in a total of 25 styles.

Additional filtering was then applied to the dataset by the creators of our model, reducing the number of images to about a half and the number of classes to 10.

The two main types of normalization used are re-scaling normalization, which normalized each pixel value of an image to a number between 0 and 1, and mean STD normalization, used to normalize data to a uniform mean of 0 and a standard deviation of 1. These two normalizations have the overall purpose of speeding up the learning process of the neural network. 


#### Who are the source language producers?

The images were taken from Wikimedia, which stores them as freely available photos taken by a large number of individual users.

### Annotations

#### Annotation process

The annotations are those used in the citated paper, and are obtained according to their classification on Wikimedia, as previously mentioned.

#### Who are the annotators?

The annotators are the authors of the referred paper, namely: Zhe Xu, Dacheng Tao, Ya Zhang, Junjie Wu, and Ah Chung Tsoi

### Personal and Sensitive Information

The dataset, owing to its content, does not contain any kind of personal or sensitive information.

## Additional Information

### Dataset Curators

The curators are the authors of the referred paper, namely: Zhe Xu, Dacheng Tao, Ya Zhang, Junjie Wu, and Ah Chung Tsoi.

### Licensing Information

This dataset is distributed using a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license.